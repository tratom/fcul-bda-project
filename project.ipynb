{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Database Project\n",
    "### Group 22\n",
    "* Enzo Chatalov - fc54414\n",
    "* Agnieszka Radomska - fc64357\n",
    "* Duarte Gonçalves - fc64465\n",
    "* Tommaso Tragno - fc64699"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "import mysql.connector\n",
    "import time\n",
    "from sqlalchemy import create_engine,text\n",
    "from sqlalchemy.exc import PendingRollbackError\n",
    "# import kagglehub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration file\n",
    "\n",
    "create a `config.json` file with the following structure:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"mongo\": {\n",
    "        \"username\": \"your_mongo_username\",\n",
    "        \"password\": \"your_mongo_password\",\n",
    "        \"host\": \"your_mongo_host\",\n",
    "        \"port\": \"your_mongo_port\"\n",
    "    },\n",
    "    \"mysql\": {\n",
    "        \"username\": \"your_mysql_username\",\n",
    "        \"password\": \"your_mysql_password\",\n",
    "        \"host\": \"your_mysql_host\",\n",
    "        \"port\": \"your_mysql_port\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load configuration file with password for mongoDB and mySQL\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Extract username and password for MongoDB and MySQL\n",
    "mongo_username = config[\"mongo\"][\"username\"]\n",
    "mongo_password = config[\"mongo\"][\"password\"]\n",
    "mongo_host = config[\"mongo\"][\"host\"]\n",
    "mongo_port = config[\"mongo\"][\"port\"]\n",
    "mysql_username = config[\"mysql\"][\"username\"]\n",
    "mysql_password = config[\"mysql\"][\"password\"]\n",
    "mysql_host = config[\"mysql\"][\"host\"]\n",
    "mysql_port = config[\"mysql\"][\"port\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest dataset version for books recommendation\n",
    "# path = kagglehub.dataset_download(\"arashnic/book-recommendation-dataset\")\n",
    "\n",
    "# Manual path specification\n",
    "path = './kagglehub/datasets/arashnic/book-recommendation-dataset/versions/3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data validation\n",
    "1. Load the `.csv` file from the path specified;\n",
    "2. Drop the rows that do not contains a primary key\n",
    "3. Fill the `na` cells with a predefined value\n",
    "4. Drop eventualy doplicates\n",
    "5. Convert the string data into the proper data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check NA values presence before data validation:\n",
      "Books data frame: True\n",
      "Ratings data frame: False\n",
      "Users data frame: True\n",
      "\n",
      "Check missing values for primary key columns:\n",
      "Dropped 0 rows form Users\n",
      "Dropped 0 rows from Books\n",
      "Dropped 0 rows from Ratings\n",
      "\n",
      "Check duplicated rows:\n",
      "Dropped 0 duplicated rows form Users\n",
      "Dropped 0 duplicated rows form Books\n",
      "Dropped 0 duplicated rows form Ratings\n",
      "\n",
      "Check NA values presence after data validation:\n",
      "Books data frame: False\n",
      "Ratings data frame: False\n",
      "Users data frame: False\n"
     ]
    }
   ],
   "source": [
    "# Load dataset into pandas dataframe\n",
    "df_books = pd.read_csv(f'{path}/Books.csv')\n",
    "df_ratings = pd.read_csv(f'{path}/Ratings.csv')\n",
    "df_users = pd.read_csv(f'{path}/Users.csv')\n",
    "\n",
    "print('Check NA values presence before data validation:')\n",
    "print(f'Books data frame: {df_books.isna().any().any()}')\n",
    "print(f'Ratings data frame: {df_ratings.isna().any().any()}')\n",
    "print(f'Users data frame: {df_users.isna().any().any()}')\n",
    "\n",
    "print('\\nCheck missing values for primary key columns:')\n",
    "# Users data validation\n",
    "orig = df_users.shape[0]\n",
    "df_users = df_users.dropna(subset=['User-ID'])\n",
    "count = orig - df_users.shape[0]\n",
    "print(f'Dropped {count} rows form Users')\n",
    "df_users = df_users.fillna({'Location': 'not available', 'Age': '0'})\n",
    "\n",
    "# Books data validation\n",
    "orig = df_books.shape[0]\n",
    "df_books = df_books.dropna(subset=['ISBN'])\n",
    "count = orig - df_books.shape[0]\n",
    "print(f'Dropped {count} rows from Books')\n",
    "df_books = df_books.fillna({\n",
    "    'Book-Title': 'not available', \n",
    "    'Book-Author': 'not available', \n",
    "    'Year-Of-Publication': '0',\n",
    "    'Publisher': 'not available', \n",
    "    'Image-URL-S': 'not available', \n",
    "    'Image-URL-M': 'not available', \n",
    "    'Image-URL-L': 'not available'\n",
    "})\n",
    "\n",
    "# Ratings data validation\n",
    "orig = df_ratings.shape[0]\n",
    "df_ratings = df_ratings.dropna(subset=['User-ID', 'ISBN'])\n",
    "count = orig - df_ratings.shape[0]\n",
    "print(f'Dropped {count} rows from Ratings')\n",
    "df_ratings = df_ratings.fillna({'Book-Rating': '0'})\n",
    "\n",
    "# Tu wlatuje FIX3\n",
    "print('\\nCheck duplicated rows:')\n",
    "orig = df_users.shape[0]\n",
    "df_users = df_users.drop_duplicates()\n",
    "count = orig - df_users.shape[0]\n",
    "print(f'Dropped {count} duplicated rows form Users')\n",
    "orig = df_books.shape[0]\n",
    "df_books = df_books.drop_duplicates()\n",
    "count = orig - df_books.shape[0]\n",
    "print(f'Dropped {count} duplicated rows form Books')\n",
    "orig = df_ratings.shape[0]\n",
    "df_ratings = df_ratings.drop_duplicates()\n",
    "count = orig - df_ratings.shape[0]\n",
    "print(f'Dropped {count} duplicated rows form Ratings')\n",
    "\n",
    "# data type conversion\n",
    "df_users['User-ID'] = pd.to_numeric(df_users['User-ID'], errors='coerce').fillna(0).astype(int)\n",
    "df_users['Age'] = pd.to_numeric(df_users['Age'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "df_ratings['User-ID'] = pd.to_numeric(df_ratings['User-ID'], errors='coerce').fillna(0).astype(int)\n",
    "df_ratings['Book-Rating'] = pd.to_numeric(df_ratings['Book-Rating'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "df_books['Year-Of-Publication'] = pd.to_numeric(df_books['Year-Of-Publication'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "\n",
    "print('\\nCheck NA values presence after data validation:')\n",
    "print(f'Books data frame: {df_books.isna().any().any()}')\n",
    "print(f'Ratings data frame: {df_ratings.isna().any().any()}')\n",
    "print(f'Users data frame: {df_users.isna().any().any()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB\n",
    "## Connects and populate the No-SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB locally\n",
    "client = MongoClient(f'mongodb://{mongo_host}:{mongo_port}',\n",
    "                             username = mongo_username,\n",
    "                             password = mongo_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.drop_database(\"project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client[\"project\"]\n",
    "\n",
    "books = db[\"books\"]\n",
    "ratings = db[\"ratings\"]\n",
    "users = db[\"users\"]\n",
    "\n",
    "books.insert_many(df_books.to_dict(orient=\"records\"), ordered=False)\n",
    "ratings.insert_many(df_ratings.to_dict(orient=\"records\"), ordered=False)\n",
    "users.insert_many(df_users.to_dict(orient=\"records\"), ordered=False)\n",
    "\n",
    "print(\"Data inserted into MongoDB collections successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries\n",
    "### Simple \n",
    "#### 1- All books published in the year 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2000\n",
    "books_in_year = books.find({\"Year-Of-Publication\": year})\n",
    "print(f\"Total Number of Books Published in the year {year}: {books.count_documents({'Year-Of-Publication': year})}\")\n",
    "for book in books_in_year:\n",
    "    bookTitle = book.get(\"Book-Title\")\n",
    "    bookISBN = book.get(\"ISBN\")\n",
    "    print(f\"ISBN: {bookISBN}, Book Title: {bookTitle}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2- All users that are older than 30 years old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = 30\n",
    "users_older_than_30 = users.find({\"Age\": {\"$gt\": age}})\n",
    "print(f\"Total Number of Users older than {age}: {users.count_documents({\"Age\": {\"$gt\": age}})}\")\n",
    "for user in users_older_than_30:\n",
    "    userID = user.get(\"User-ID\")\n",
    "    print(f\"User ID: {userID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex\n",
    "#### 1- Update all ratings from UserID \"276890\" to 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userID = 276890\n",
    "print(\"Ratings before the update:\")\n",
    "for rating in ratings.find({\"User-ID\": userID}):\n",
    "    print(rating)\n",
    "\n",
    "ratings.update_many({\"User-ID\": userID}, {\"$set\": {\"Book-Rating\": 8}})\n",
    "\n",
    "print(\"Ratings after the update:\")\n",
    "for rating in ratings.find({\"User-ID\": userID}):\n",
    "    print(rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Add a new column in the Books table with the mean ratings of every book ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Calculate the mean rating for each book\n",
    "mean_ratings = df_ratings.groupby('ISBN')['Book-Rating'].mean().reset_index()\n",
    "mean_ratings.columns = ['ISBN', 'Mean-Rating']\n",
    "\n",
    "# Merge the mean ratings with the books dataframe\n",
    "df_books = pd.merge(df_books, mean_ratings, on='ISBN', how='left')\n",
    "df_books['Mean-Rating'] = round(df_books['Mean-Rating'].fillna(0),2)\n",
    "\n",
    "# Update MongoDB with the new column\n",
    "for book in df_books.to_dict(orient=\"records\"):\n",
    "    books.update_one({'ISBN': book['ISBN']}, {'$set': {'Mean-Rating': book['Mean-Rating']}})\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratings.create_index([(\"User_ID\", 1)])\n",
    "#ratings.create_index([(\"ISBN\", 1)])\n",
    "#print(\"Indexes added to MongoDB ratings collection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MySQL\n",
    "## Connects to MySql database, create the schema and populate the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to mySQL locally\n",
    "mydb = mysql.connector.connect(\n",
    "    host=mysql_host,\n",
    "    port=mysql_port,\n",
    "    user=mysql_username,\n",
    "    password=mysql_password\n",
    ")\n",
    "\n",
    "cursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"DROP DATABASE IF EXISTS project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"CREATE DATABASE IF NOT EXISTS project\")\n",
    "cursor.execute(\"USE project\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS users (\n",
    "        user_id INT PRIMARY KEY,\n",
    "        location VARCHAR(255),\n",
    "        age INT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS books (\n",
    "        ISBN VARCHAR(20) PRIMARY KEY,\n",
    "        Book_Title VARCHAR(255),\n",
    "        Book_Author VARCHAR(255),\n",
    "        Year_Of_Publication INT,\n",
    "        Publisher VARCHAR(255),\n",
    "        Image_URL_S VARCHAR(255),\n",
    "        Image_URL_M VARCHAR(255),\n",
    "        Image_URL_L VARCHAR(255),\n",
    "        Global_Rating FLOAT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS ratings (\n",
    "        User_ID INT,\n",
    "        ISBN VARCHAR(20),\n",
    "        Book_Rating INT,\n",
    "        FOREIGN KEY (User_ID) REFERENCES users(user_id),\n",
    "        FOREIGN KEY (ISBN) REFERENCES books(ISBN),\n",
    "        PRIMARY KEY (User_ID, ISBN)\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# added try - except statement to catch the problematic rows\n",
    "for _, row in df_books.iterrows():\n",
    "    try:\n",
    "        cursor.execute(\n",
    "            \"INSERT IGNORE INTO books (ISBN, Book_Title, Book_Author, Year_Of_Publication, Publisher, Image_URL_S, Image_URL_M, Image_URL_L) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\",\n",
    "            (row['ISBN'], row['Book-Title'], row['Book-Author'], row['Year-Of-Publication'], row['Publisher'], row['Image-URL-S'], row['Image-URL-M'], row['Image-URL-L'])\n",
    "        )\n",
    "    except:\n",
    "        print(row)\n",
    "\n",
    "for _, row in df_users.iterrows():\n",
    "    try:\n",
    "        cursor.execute(\n",
    "            \"INSERT IGNORE INTO users (user_id, location, age) VALUES (%s, %s, %s)\",\n",
    "            (row['User-ID'], row['Location'], row['Age']) # Tutaj wleciał FIX1\n",
    "        )\n",
    "    except:\n",
    "        print(row)\n",
    "\n",
    "for _, row in df_ratings.iterrows():\n",
    "    try:\n",
    "        cursor.execute(\n",
    "            \"INSERT IGNORE INTO ratings (User_ID, ISBN, Book_Rating) VALUES (%s, %s, %s)\",\n",
    "            (row['User-ID'], row['ISBN'], row['Book-Rating'])\n",
    "        )\n",
    "    except:\n",
    "        print(row)\n",
    "\n",
    "mydb.commit()\n",
    "\n",
    "print(\"Data inserted successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries\n",
    "### Simple\n",
    "#### 1- All books published in the year 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT ISBN, Book_Title FROM books WHERE Year_Of_Publication = 2000\")\n",
    "sql_books_in_year = cursor.fetchall()\n",
    "print(f'There are {len(sql_books_in_year)} users older than 30 years:')\n",
    "for book in sql_books_in_year:\n",
    "    bookTitle = book[1]\n",
    "    bookISBN = book[0]\n",
    "    print(f\"ISBN: {bookISBN}, Book Title: {bookTitle}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2- All users that are older than 30 years old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT user_id FROM users WHERE age > 30\")\n",
    "sql_users_above_30 = cursor.fetchall()\n",
    "print(f'There are {len(sql_users_above_30)} users older than 30 years:')\n",
    "for user in sql_users_above_30:\n",
    "    print(f\"UserID: {user[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex\n",
    "#### 1- Update all ratings from UserID \"276890\" to 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userID = 276890\n",
    "new_rating = 8\n",
    "\n",
    "print(\"Ratings before the update:\")\n",
    "cursor.execute(\"SELECT * FROM ratings WHERE User_ID = %s\", (userID,))\n",
    "for rating in cursor.fetchall():\n",
    "    print(rating)\n",
    "\n",
    "cursor.execute(\"UPDATE ratings SET Book_Rating = %s WHERE User_ID = %s\", (new_rating, userID))\n",
    "mydb.commit()\n",
    "\n",
    "print(\"Ratings after the update:\")\n",
    "cursor.execute(\"SELECT * FROM ratings WHERE User_ID = %s\", (userID,))\n",
    "for rating in cursor.fetchall():\n",
    "    print(rating)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Add a new column in the Books table with the mean ratings of every book ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Calculate the mean rating for each book\n",
    "mean_ratings = df_ratings.groupby('ISBN')['Book-Rating'].mean().reset_index()\n",
    "mean_ratings.columns = ['ISBN', 'Mean-Rating']\n",
    "\n",
    "# Merge the mean ratings with the books dataframe\n",
    "df_books = pd.merge(df_books, mean_ratings, on='ISBN', how='left')\n",
    "df_books['Mean-Rating'] = round(df_books['Mean-Rating'].fillna(0), 2)\n",
    "\n",
    "# Update MySQL with the new column\n",
    "cursor.execute(\"ALTER TABLE books ADD COLUMN Mean_Rating FLOAT\")\n",
    "for _, row in df_books.iterrows():\n",
    "    cursor.execute(\n",
    "        \"UPDATE books SET Mean_Rating = %s WHERE ISBN = %s\",\n",
    "        (row['Mean-Rating'], row['ISBN'])\n",
    "    )\n",
    "mydb.commit()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"CREATE INDEX idx_user_id ON ratings(User_ID)\")\n",
    "cursor.execute(\"CREATE INDEX idx_isbn ON ratings(ISBN)\")\n",
    "print(\"Indexes added to Ratings table.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "cursor.execute(\"SELECT * FROM ratings WHERE User_ID = 1\")\n",
    "cursor.fetchall()\n",
    "end_time = time.time()\n",
    "print(\"MySQL query time:\", end_time - start_time)\n",
    "\n",
    "start_time = time.time()\n",
    "list(ratings.find({\"User_ID\": 1}))\n",
    "end_time = time.time()\n",
    "print(\"MongoDB query time:\", end_time - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
